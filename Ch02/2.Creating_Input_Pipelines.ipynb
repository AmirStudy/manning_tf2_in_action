{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data retrieval and processing in TensorFlow and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "    <td>\n",
    "        <a target=\"_blank\" href=\"https://colab.research.google.com/github/thushv89/manning_tf2_in_action/blob/master/Ch02/2.Creating_Input_Pipelines.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "    </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries and some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def fix_random_seed(seed):\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: Numpy is not imported. Setting the seed for Numpy failed.\")\n",
    "    try:\n",
    "        tf.random.set_seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: TensorFlow is not imported. Setting the seed for TensorFlow failed.\")\n",
    "    try:\n",
    "        random.seed(seed)\n",
    "    except NameError:\n",
    "        print(\"Warning: random module is not imported. Setting the seed for random failed.\")\n",
    "\n",
    "# Fixing the random seed\n",
    "fix_random_seed(4321)\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `tf.data` API to retrieve data\n",
    "\n",
    "Here we will be using the `tf.data` API to feed a dataset containing images of flowers. The dataset has a folder containing the images and a CSV file listing filenames and their corresponding label as an integer. We will write a TensorFlow data pipeline that does the following.\n",
    "\n",
    "* Extract filenames and classes from the CSV\n",
    "* Read in the images from the extracted filenames and resize them to 64x64\n",
    "* Convert the class labels to one-hot encoded vectors\n",
    "* Combine the processed images and one-hot encoded vectors to a single dataset\n",
    "* Finally, shuffle the data and output as batches\n",
    "\n",
    "### Downloading the data\n",
    "The dataset is available at https://www.kaggle.com/olgabelitskaya/flower-color-images/data . \n",
    "\n",
    "You need to download the zip file available in this URL and place it in the `data` folder in the `Ch02` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Extracting the flowers image data to a directory\n",
    "if os.path.exists('data/flower-color-images.zip'):\n",
    "    zfile = ZipFile('data/flower-color-images.zip')\n",
    "    zfile.extractall('data')\n",
    "else:\n",
    "    print(\"Did you download the dataset as a zip file and place it in the Ch02/data folder?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a tf.data.Dataset \n",
    "\n",
    "Here we are creating the `tf.data` pipeline that executes the above steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image dataset contains: <MapDataset shapes: (64, 64, 3), types: tf.float32>\n",
      "(<tf.Tensor: shape=(5, 64, 64, 3), dtype=float32, numpy=\n",
      "array([[[[0.33823532, 0.5235294 , 0.7205882 ],\n",
      "         [0.3421569 , 0.5254902 , 0.72156864],\n",
      "         [0.34117648, 0.5245098 , 0.72450984],\n",
      "         ...,\n",
      "         [0.34313726, 0.52745104, 0.72745097],\n",
      "         [0.34117648, 0.5254902 , 0.7264706 ],\n",
      "         [0.34411764, 0.5284314 , 0.7254902 ]],\n",
      "\n",
      "        [[0.34117648, 0.5245098 , 0.7264706 ],\n",
      "         [0.34019607, 0.52745104, 0.72156864],\n",
      "         [0.3392157 , 0.5235294 , 0.7254902 ],\n",
      "         ...,\n",
      "         [0.34509805, 0.5284314 , 0.7294118 ],\n",
      "         [0.34411764, 0.5284314 , 0.7294118 ],\n",
      "         [0.34313726, 0.5284314 , 0.72843134]],\n",
      "\n",
      "        [[0.34313726, 0.52647066, 0.72156864],\n",
      "         [0.34117648, 0.5284314 , 0.72352946],\n",
      "         [0.34411764, 0.5254902 , 0.7235294 ],\n",
      "         ...,\n",
      "         [0.34411764, 0.5284314 , 0.7294118 ],\n",
      "         [0.34509805, 0.5294118 , 0.7294118 ],\n",
      "         [0.34607846, 0.53039217, 0.72843134]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.3647059 , 0.54901963, 0.7490196 ],\n",
      "         [0.3647059 , 0.5500001 , 0.7460785 ],\n",
      "         [0.3656863 , 0.55098045, 0.7460785 ],\n",
      "         ...,\n",
      "         [0.36862746, 0.5529412 , 0.75294125],\n",
      "         [0.36666667, 0.55098045, 0.75294125],\n",
      "         [0.3656863 , 0.5500001 , 0.7519609 ]],\n",
      "\n",
      "        [[0.36666667, 0.54901963, 0.7490196 ],\n",
      "         [0.3647059 , 0.5500001 , 0.74705887],\n",
      "         [0.3656863 , 0.55098045, 0.74803925],\n",
      "         ...,\n",
      "         [0.3647059 , 0.55490196, 0.75294125],\n",
      "         [0.36862746, 0.55490196, 0.7460785 ],\n",
      "         [0.36764705, 0.5519608 , 0.7519609 ]],\n",
      "\n",
      "        [[0.3627451 , 0.55098045, 0.74509805],\n",
      "         [0.36666667, 0.5500001 , 0.7490196 ],\n",
      "         [0.3656863 , 0.55098045, 0.74803925],\n",
      "         ...,\n",
      "         [0.3647059 , 0.5539216 , 0.75294125],\n",
      "         [0.36764705, 0.5519608 , 0.754902  ],\n",
      "         [0.3656863 , 0.5539216 , 0.7490196 ]]],\n",
      "\n",
      "\n",
      "       [[[0.01470588, 0.01470588, 0.01470588],\n",
      "         [0.01764706, 0.01764706, 0.01764706],\n",
      "         [0.02941177, 0.02843137, 0.02843137],\n",
      "         ...,\n",
      "         [0.01568628, 0.01568628, 0.01568628],\n",
      "         [0.01568628, 0.01372549, 0.01372549],\n",
      "         [0.02352941, 0.02352941, 0.02352941]],\n",
      "\n",
      "        [[0.02254902, 0.02156863, 0.02156863],\n",
      "         [0.02058824, 0.02058824, 0.02058824],\n",
      "         [0.02058824, 0.02058824, 0.02058824],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.01078431, 0.01078431, 0.01078431],\n",
      "         [0.01764706, 0.01666667, 0.01666667]],\n",
      "\n",
      "        [[0.01960785, 0.01862745, 0.01862745],\n",
      "         [0.02254902, 0.02156863, 0.02058824],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00882353, 0.00882353, 0.00882353],\n",
      "         [0.0254902 , 0.02745098, 0.02450981]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.09705883, 0.14705883, 0.05588236],\n",
      "         [0.10294119, 0.1647059 , 0.05686275],\n",
      "         [0.12156864, 0.17450982, 0.06176471],\n",
      "         ...,\n",
      "         [0.04215686, 0.04215686, 0.04215686],\n",
      "         [0.03921569, 0.04019608, 0.04019608],\n",
      "         [0.04313726, 0.04313726, 0.04313726]],\n",
      "\n",
      "        [[0.07941177, 0.1137255 , 0.05588236],\n",
      "         [0.09803922, 0.14019608, 0.06372549],\n",
      "         [0.1009804 , 0.14411765, 0.06176471],\n",
      "         ...,\n",
      "         [0.04411765, 0.04411765, 0.04411765],\n",
      "         [0.04411765, 0.04411765, 0.04411765],\n",
      "         [0.04313726, 0.04313726, 0.04313726]],\n",
      "\n",
      "        [[0.07156863, 0.10392158, 0.05294118],\n",
      "         [0.08333334, 0.11666667, 0.05784314],\n",
      "         [0.07843138, 0.1137255 , 0.05588236],\n",
      "         ...,\n",
      "         [0.05      , 0.05      , 0.05      ],\n",
      "         [0.04411765, 0.04411765, 0.04411765],\n",
      "         [0.04117647, 0.04215686, 0.04215686]]],\n",
      "\n",
      "\n",
      "       [[[0.21078433, 0.30490196, 0.21862747],\n",
      "         [0.21078433, 0.30490196, 0.22352943],\n",
      "         [0.2137255 , 0.30490196, 0.21764708],\n",
      "         ...,\n",
      "         [0.10882354, 0.17941177, 0.07843138],\n",
      "         [0.10588236, 0.18823531, 0.07745098],\n",
      "         [0.09313726, 0.17156863, 0.06666667]],\n",
      "\n",
      "        [[0.22156864, 0.32058823, 0.23235296],\n",
      "         [0.21666668, 0.31764707, 0.22941178],\n",
      "         [0.22058825, 0.31960785, 0.22058825],\n",
      "         ...,\n",
      "         [0.14803922, 0.23137257, 0.11764707],\n",
      "         [0.14607844, 0.23039217, 0.11078432],\n",
      "         [0.10490197, 0.18137257, 0.07843138]],\n",
      "\n",
      "        [[0.21274512, 0.3156863 , 0.22254904],\n",
      "         [0.21078433, 0.31176472, 0.22450982],\n",
      "         [0.2137255 , 0.3147059 , 0.22352943],\n",
      "         ...,\n",
      "         [0.19313726, 0.26862746, 0.14607844],\n",
      "         [0.18039218, 0.25980395, 0.13431373],\n",
      "         [0.11764707, 0.19215688, 0.09019609]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.29901963, 0.43333334, 0.29313725],\n",
      "         [0.25      , 0.34705883, 0.23039217],\n",
      "         [0.3254902 , 0.4421569 , 0.28039217],\n",
      "         ...,\n",
      "         [0.17843138, 0.27745098, 0.16078432],\n",
      "         [0.18431374, 0.28627452, 0.16764706],\n",
      "         [0.18039216, 0.28039217, 0.16176471]],\n",
      "\n",
      "        [[0.4166667 , 0.59019613, 0.31764707],\n",
      "         [0.37254903, 0.5480392 , 0.28431374],\n",
      "         [0.33235294, 0.51862746, 0.22549021],\n",
      "         ...,\n",
      "         [0.16666667, 0.2676471 , 0.14901961],\n",
      "         [0.18039218, 0.2784314 , 0.16176471],\n",
      "         [0.1754902 , 0.28039217, 0.15980393]],\n",
      "\n",
      "        [[0.36666667, 0.6058824 , 0.18039218],\n",
      "         [0.3892157 , 0.6156863 , 0.2019608 ],\n",
      "         [0.3950981 , 0.61372554, 0.2137255 ],\n",
      "         ...,\n",
      "         [0.17647061, 0.27058825, 0.15882353],\n",
      "         [0.17843139, 0.28039217, 0.1627451 ],\n",
      "         [0.19215688, 0.3019608 , 0.1754902 ]]],\n",
      "\n",
      "\n",
      "       [[[0.28921568, 0.26568627, 0.23431374],\n",
      "         [0.28333336, 0.31764707, 0.21960786],\n",
      "         [0.25980395, 0.31078434, 0.19509806],\n",
      "         ...,\n",
      "         [0.22843139, 0.2137255 , 0.18725492],\n",
      "         [0.28431374, 0.25980395, 0.22450982],\n",
      "         [0.3147059 , 0.27450982, 0.21960786]],\n",
      "\n",
      "        [[0.34411764, 0.31862748, 0.28333336],\n",
      "         [0.33529413, 0.34509805, 0.26372552],\n",
      "         [0.26862746, 0.30686277, 0.19607845],\n",
      "         ...,\n",
      "         [0.28725493, 0.27156866, 0.2137255 ],\n",
      "         [0.31666666, 0.29607844, 0.21764708],\n",
      "         [0.23235296, 0.2137255 , 0.15784314]],\n",
      "\n",
      "        [[0.32254905, 0.33333334, 0.2617647 ],\n",
      "         [0.29901963, 0.33333334, 0.23823531],\n",
      "         [0.23725492, 0.29803923, 0.17843139],\n",
      "         ...,\n",
      "         [0.28529412, 0.28333336, 0.18431374],\n",
      "         [0.18039218, 0.18333334, 0.13039216],\n",
      "         [0.13431373, 0.1382353 , 0.11568628]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10980393, 0.19313727, 0.07058824],\n",
      "         [0.11176471, 0.2029412 , 0.07647059],\n",
      "         [0.1137255 , 0.20980394, 0.08039216],\n",
      "         ...,\n",
      "         [0.14705883, 0.14411765, 0.1264706 ],\n",
      "         [0.1254902 , 0.1254902 , 0.11274511],\n",
      "         [0.1382353 , 0.1392157 , 0.1264706 ]],\n",
      "\n",
      "        [[0.20098041, 0.21666668, 0.15      ],\n",
      "         [0.17156863, 0.20784315, 0.1264706 ],\n",
      "         [0.13431373, 0.20490198, 0.09901962],\n",
      "         ...,\n",
      "         [0.15196079, 0.14901961, 0.12941177],\n",
      "         [0.13725491, 0.13529412, 0.12156864],\n",
      "         [0.14705883, 0.15      , 0.13431373]],\n",
      "\n",
      "        [[0.23627453, 0.21176472, 0.18235296],\n",
      "         [0.19215688, 0.17843139, 0.15882353],\n",
      "         [0.15196079, 0.15294118, 0.1264706 ],\n",
      "         ...,\n",
      "         [0.14215687, 0.1392157 , 0.12156864],\n",
      "         [0.1382353 , 0.13529412, 0.12058824],\n",
      "         [0.13333334, 0.13529412, 0.11960785]]],\n",
      "\n",
      "\n",
      "       [[[0.22549021, 0.3509804 , 0.14411765],\n",
      "         [0.20098041, 0.33529413, 0.14901961],\n",
      "         [0.19411767, 0.32352942, 0.14705883],\n",
      "         ...,\n",
      "         [0.09509805, 0.13725491, 0.09313726],\n",
      "         [0.09803922, 0.13725491, 0.09215687],\n",
      "         [0.09901962, 0.1392157 , 0.09215687]],\n",
      "\n",
      "        [[0.24607845, 0.3882353 , 0.16176471],\n",
      "         [0.2137255 , 0.3480392 , 0.14607844],\n",
      "         [0.21176472, 0.3509804 , 0.14607844],\n",
      "         ...,\n",
      "         [0.11176471, 0.14509805, 0.08627451],\n",
      "         [0.09705883, 0.13529412, 0.0754902 ],\n",
      "         [0.09117648, 0.13431373, 0.07450981]],\n",
      "\n",
      "        [[0.227451  , 0.38333338, 0.15294118],\n",
      "         [0.22058825, 0.36666667, 0.15588236],\n",
      "         [0.2147059 , 0.35588235, 0.14705883],\n",
      "         ...,\n",
      "         [0.12352942, 0.16666667, 0.10000001],\n",
      "         [0.11960785, 0.16666667, 0.1009804 ],\n",
      "         [0.1137255 , 0.15882353, 0.09215687]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10000001, 0.19411767, 0.0754902 ],\n",
      "         [0.11568628, 0.20098041, 0.09215687],\n",
      "         [0.1264706 , 0.2137255 , 0.10294119],\n",
      "         ...,\n",
      "         [0.43921572, 0.5872549 , 0.25980395],\n",
      "         [0.41176474, 0.57254905, 0.23039217],\n",
      "         [0.43921572, 0.59803927, 0.24411766]],\n",
      "\n",
      "        [[0.1009804 , 0.18823531, 0.07450981],\n",
      "         [0.10686275, 0.19705884, 0.08627451],\n",
      "         [0.11862746, 0.20392159, 0.1009804 ],\n",
      "         ...,\n",
      "         [0.43137258, 0.5852941 , 0.23529413],\n",
      "         [0.44509807, 0.59411764, 0.24313727],\n",
      "         [0.4519608 , 0.6       , 0.2509804 ]],\n",
      "\n",
      "        [[0.10784315, 0.19117649, 0.07745098],\n",
      "         [0.10588236, 0.19411767, 0.09019609],\n",
      "         [0.12058824, 0.19803923, 0.10392158],\n",
      "         ...,\n",
      "         [0.41274512, 0.5647059 , 0.21960786],\n",
      "         [0.4294118 , 0.5735294 , 0.2392157 ],\n",
      "         [0.46764708, 0.6117647 , 0.26960784]]]], dtype=float32)>, <tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "# Code listing 2.8\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session() # Making sure we are clearing out the TensorFlow graph\n",
    "\n",
    "# Read the CSV file with TensorFlow\n",
    "# The os.path.sep at the end is important for the get_image function\n",
    "data_dir = os.path.join('data','flower_images', 'flower_images') + os.path.sep\n",
    "assert os.path.exists(data_dir)\n",
    "csv_ds = tf.data.experimental.CsvDataset(\n",
    "    os.path.join(data_dir,'flower_labels.csv') , (\"\",-1), header=True\n",
    ")\n",
    "# Separate the image names and labels to two separate sets\n",
    "fname_ds = csv_ds.map(lambda a,b: a)\n",
    "label_ds = csv_ds.map(lambda a,b: b)\n",
    "\n",
    "def get_image(file_path):\n",
    "    \n",
    "    img = tf.io.read_file(data_dir + file_path)\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [64, 64])\n",
    "\n",
    "# Get the images by running get_image across all the filenames\n",
    "image_ds = fname_ds.map(get_image)\n",
    "print(\"The image dataset contains: {}\".format(image_ds))\n",
    "# Create onehot encoded labels from label data\n",
    "label_ds = label_ds.map(lambda x: tf.one_hot(x, depth=10))\n",
    "# Zip the images and labels together\n",
    "data_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "\n",
    "# Shuffle the data so that we get a mix of labels in every batch\n",
    "data_ds = data_ds.shuffle(buffer_size= 20)\n",
    "# Define a batch of size 5 \n",
    "data_ds = data_ds.batch(5)\n",
    "# Iterate through the data to see what it contains\n",
    "for item in data_ds:\n",
    "    print(item)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and training a model\n",
    "\n",
    "Here we are defining a simple Convolution Neural Network (CNN) model to train it on the image data we just retrieved. You don't have to worry about the technical details of CNNs right now. We will discuss them in detail in the next chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "      1/Unknown - 2s 2s/step"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-2-973f607bb1ff>:19) ]] [Op:__inference_distributed_function_679]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-973f607bb1ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Training the model with the tf.data pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mc:\\anaconda3\\envs\\manning.tf2\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-2-973f607bb1ff>:19) ]] [Op:__inference_distributed_function_679]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Defining a Convolution neural network for you to train for the flowers data\n",
    "# We will discuss convolution neural networks in more detail later\n",
    "model = Sequential([\n",
    "    Conv2D(64,(5,5), activation='relu', input_shape=(64,64,3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# Training the model with the tf.data pipeline\n",
    "model.fit(data_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras data generators to retrieve data\n",
    "\n",
    "Instead of `tf.data` API let us use the Keras `ImageDataGenerator` to retrieve the data. As you can see, the `ImageDataGenerator` involves much less code than the using the `tf.data` API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 validated image filenames.\n",
      "(array([[[[ 26.,  31.,  18.],\n",
      "         [ 26.,  31.,  20.],\n",
      "         [ 21.,  23.,  15.],\n",
      "         ...,\n",
      "         [ 45.,  53.,  41.],\n",
      "         [ 24.,  29.,  21.],\n",
      "         [ 17.,  20.,  14.]],\n",
      "\n",
      "        [[ 41.,  52.,  27.],\n",
      "         [ 43.,  54.,  29.],\n",
      "         [ 33.,  42.,  23.],\n",
      "         ...,\n",
      "         [ 54.,  61.,  47.],\n",
      "         [ 42.,  47.,  34.],\n",
      "         [ 43.,  47.,  33.]],\n",
      "\n",
      "        [[ 51.,  67.,  32.],\n",
      "         [ 52.,  69.,  28.],\n",
      "         [ 41.,  53.,  28.],\n",
      "         ...,\n",
      "         [ 88.,  94.,  54.],\n",
      "         [ 93.,  94.,  50.],\n",
      "         [108., 104.,  55.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 83., 101.,  58.],\n",
      "         [ 93.,  77.,  60.],\n",
      "         [107.,  88.,  77.],\n",
      "         ...,\n",
      "         [ 55.,  46.,  44.],\n",
      "         [ 52.,  44.,  41.],\n",
      "         [ 48.,  41.,  38.]],\n",
      "\n",
      "        [[ 37.,  51.,  35.],\n",
      "         [ 86.,  76.,  58.],\n",
      "         [100.,  86.,  72.],\n",
      "         ...,\n",
      "         [ 53.,  45.,  42.],\n",
      "         [ 53.,  44.,  41.],\n",
      "         [ 52.,  43.,  41.]],\n",
      "\n",
      "        [[ 29.,  40.,  25.],\n",
      "         [ 71.,  70.,  54.],\n",
      "         [ 97.,  83.,  71.],\n",
      "         ...,\n",
      "         [ 53.,  46.,  40.],\n",
      "         [ 53.,  46.,  42.],\n",
      "         [ 59.,  51.,  48.]]],\n",
      "\n",
      "\n",
      "       [[[ 63., 105.,  46.],\n",
      "         [ 37.,  60.,  27.],\n",
      "         [ 26.,  38.,  21.],\n",
      "         ...,\n",
      "         [ 32.,  42.,  28.],\n",
      "         [ 21.,  26.,  21.],\n",
      "         [ 48.,  60.,  42.]],\n",
      "\n",
      "        [[ 58.,  77.,  44.],\n",
      "         [ 31.,  49.,  26.],\n",
      "         [ 27.,  47.,  21.],\n",
      "         ...,\n",
      "         [ 95., 111.,  91.],\n",
      "         [ 41.,  64.,  39.],\n",
      "         [ 42.,  61.,  36.]],\n",
      "\n",
      "        [[ 23.,  58.,  22.],\n",
      "         [ 15.,  25.,  16.],\n",
      "         [ 39.,  65.,  31.],\n",
      "         ...,\n",
      "         [ 77., 122.,  65.],\n",
      "         [ 91., 100.,  87.],\n",
      "         [ 35.,  49.,  34.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 58., 107.,  33.],\n",
      "         [ 78., 124.,  47.],\n",
      "         [ 78., 125.,  50.],\n",
      "         ...,\n",
      "         [137., 149., 122.],\n",
      "         [ 68.,  91.,  52.],\n",
      "         [ 39.,  55.,  35.]],\n",
      "\n",
      "        [[ 46.,  53.,  41.],\n",
      "         [ 57.,  70.,  49.],\n",
      "         [112., 151.,  79.],\n",
      "         ...,\n",
      "         [ 96., 124.,  73.],\n",
      "         [116., 136.,  99.],\n",
      "         [ 65.,  89.,  57.]],\n",
      "\n",
      "        [[210., 211., 210.],\n",
      "         [210., 211., 210.],\n",
      "         [212., 212., 212.],\n",
      "         ...,\n",
      "         [209., 209., 210.],\n",
      "         [209., 208., 210.],\n",
      "         [216., 217., 213.]]]], dtype=float32), array([5, 8], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Code listing 2.9\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = os.path.join('data','flower_images', 'flower_images')\n",
    "\n",
    "# Defining an image data generator provided in Keras\n",
    "img_gen = ImageDataGenerator()\n",
    "\n",
    "# Reading the CSV files containing filenames and labels\n",
    "labels_df = pd.read_csv(os.path.join(data_dir, 'flower_labels.csv'), header=0)\n",
    "\n",
    "# Generating data using the flow_from_dataframe function\n",
    "gen_iter = img_gen.flow_from_dataframe(\n",
    "    dataframe=labels_df, directory=data_dir, x_col='file', y_col='label', class_mode='raw', batch_size=2, target_size=(64,64))\n",
    "\n",
    "# Iterating through the data\n",
    "for item in gen_iter:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `tensorflow-datasets` library\n",
    "\n",
    "Here we will use the `tensorflow-datasets` package. It is a curated list of popular datasets available for machine learning projects. With this package you can download a dataset in a single line. This means you don't have to worry about downloading/extracting/formatting data manually. All of that will be already done when you import data using the `tensorflow-datasets` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists the available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'amazon_us_reviews',\n",
       " 'arc',\n",
       " 'bair_robot_pushing_small',\n",
       " 'beans',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'c4',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'cos_e',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'downsampled_imagenet',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'dummy_dataset_shared_generator',\n",
       " 'dummy_mnist',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'gap',\n",
       " 'gigaword',\n",
       " 'glue',\n",
       " 'groove',\n",
       " 'higgs',\n",
       " 'horses_or_humans',\n",
       " 'i_naturalist2017',\n",
       " 'image_label_folder',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet_resized',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'iris',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'lm1b',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_rationales',\n",
       " 'moving_mnist',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_questions',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'omniglot',\n",
       " 'open_images_v4',\n",
       " 'opinosis',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'patch_camelyon',\n",
       " 'pet_finder',\n",
       " 'places365_small',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'qa4mre',\n",
       " 'quickdraw_bitmap',\n",
       " 'reddit_tifu',\n",
       " 'resisc45',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'shapes3d',\n",
       " 'smallnorb',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'squad',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'starcraft_video',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trivia_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'vgg_face2',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'wider_face',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'xnli',\n",
       " 'xsum',\n",
       " 'yelp_polarity_reviews']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "# See all registered datasets\n",
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Cifar10 dataset and view information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='cifar10',\n",
      "    version=3.0.0,\n",
      "    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',\n",
      "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    total_num_examples=60000,\n",
      "    splits={\n",
      "        'test': 10000,\n",
      "        'train': 50000,\n",
      "    },\n",
      "    supervised_keys=('image', 'label'),\n",
      "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
      "        author = {Alex Krizhevsky},\n",
      "        title = {Learning multiple layers of features from tiny images},\n",
      "        institution = {},\n",
      "        year = {2009}\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.clear_session() # Making sure we are clearing out the TensorFlow graph\n",
    "\n",
    "# Load a given dataset by name, along with the DatasetInfo\n",
    "data, info = tfds.load(\"cifar10\", with_info=True)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data \n",
    "\n",
    "Here we will print the `data` and see what it provides. Then we will need to batch the data as data is provided as individual samples when you import it from `tensorflow-datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': <DatasetV1Adapter shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>, 'train': <DatasetV1Adapter shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(16, 32, 32, 3), dtype=uint8, numpy=\n",
      "array([[[[143,  96,  70],\n",
      "         [141,  96,  72],\n",
      "         [135,  93,  72],\n",
      "         ...,\n",
      "         [ 96,  37,  19],\n",
      "         [105,  42,  18],\n",
      "         [104,  38,  20]],\n",
      "\n",
      "        [[128,  98,  92],\n",
      "         [146, 118, 112],\n",
      "         [170, 145, 138],\n",
      "         ...,\n",
      "         [108,  45,  26],\n",
      "         [112,  44,  24],\n",
      "         [112,  41,  22]],\n",
      "\n",
      "        [[ 93,  69,  75],\n",
      "         [118,  96, 101],\n",
      "         [179, 160, 162],\n",
      "         ...,\n",
      "         [128,  68,  47],\n",
      "         [125,  61,  42],\n",
      "         [122,  59,  39]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[187, 150, 123],\n",
      "         [184, 148, 123],\n",
      "         [179, 142, 121],\n",
      "         ...,\n",
      "         [198, 163, 132],\n",
      "         [201, 166, 135],\n",
      "         [207, 174, 143]],\n",
      "\n",
      "        [[187, 150, 117],\n",
      "         [181, 143, 115],\n",
      "         [175, 136, 113],\n",
      "         ...,\n",
      "         [201, 164, 132],\n",
      "         [205, 168, 135],\n",
      "         [207, 171, 139]],\n",
      "\n",
      "        [[195, 161, 126],\n",
      "         [187, 153, 123],\n",
      "         [186, 151, 128],\n",
      "         ...,\n",
      "         [212, 177, 147],\n",
      "         [219, 185, 155],\n",
      "         [221, 187, 157]]],\n",
      "\n",
      "\n",
      "       [[[203, 214, 234],\n",
      "         [191, 207, 226],\n",
      "         [178, 200, 224],\n",
      "         ...,\n",
      "         [127, 172, 213],\n",
      "         [126, 171, 212],\n",
      "         [124, 170, 211]],\n",
      "\n",
      "        [[205, 214, 230],\n",
      "         [186, 199, 213],\n",
      "         [180, 197, 214],\n",
      "         ...,\n",
      "         [132, 178, 219],\n",
      "         [130, 176, 219],\n",
      "         [129, 175, 217]],\n",
      "\n",
      "        [[193, 200, 213],\n",
      "         [141, 151, 159],\n",
      "         [124, 137, 145],\n",
      "         ...,\n",
      "         [136, 178, 218],\n",
      "         [134, 177, 218],\n",
      "         [132, 176, 217]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 40,  47,  56],\n",
      "         [ 33,  37,  42],\n",
      "         [ 31,  35,  41],\n",
      "         ...,\n",
      "         [ 73,  99, 132],\n",
      "         [ 64,  91, 126],\n",
      "         [ 69,  97, 133]],\n",
      "\n",
      "        [[ 37,  44,  53],\n",
      "         [ 31,  34,  40],\n",
      "         [ 30,  34,  40],\n",
      "         ...,\n",
      "         [ 72,  98, 132],\n",
      "         [ 64,  92, 127],\n",
      "         [ 68,  96, 132]],\n",
      "\n",
      "        [[ 34,  41,  50],\n",
      "         [ 29,  32,  38],\n",
      "         [ 28,  32,  38],\n",
      "         ...,\n",
      "         [ 68,  94, 127],\n",
      "         [ 62,  89, 123],\n",
      "         [ 63,  91, 126]]],\n",
      "\n",
      "\n",
      "       [[[106, 103, 104],\n",
      "         [103,  97,  99],\n",
      "         [102,  93,  96],\n",
      "         ...,\n",
      "         [135, 126, 129],\n",
      "         [139, 130, 133],\n",
      "         [131, 122, 125]],\n",
      "\n",
      "        [[106, 104, 105],\n",
      "         [105,  99, 101],\n",
      "         [115, 106, 109],\n",
      "         ...,\n",
      "         [137, 129, 132],\n",
      "         [135, 126, 129],\n",
      "         [124, 115, 118]],\n",
      "\n",
      "        [[108, 105, 106],\n",
      "         [117, 111, 113],\n",
      "         [123, 114, 117],\n",
      "         ...,\n",
      "         [132, 123, 126],\n",
      "         [126, 117, 120],\n",
      "         [121, 112, 115]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[136, 163, 117],\n",
      "         [135, 162, 115],\n",
      "         [139, 166, 117],\n",
      "         ...,\n",
      "         [140, 144, 111],\n",
      "         [133, 135, 105],\n",
      "         [126, 125,  98]],\n",
      "\n",
      "        [[130, 150, 104],\n",
      "         [131, 150, 107],\n",
      "         [131, 150, 109],\n",
      "         ...,\n",
      "         [141, 150, 112],\n",
      "         [144, 152, 115],\n",
      "         [140, 144, 111]],\n",
      "\n",
      "        [[139, 151, 108],\n",
      "         [133, 144, 103],\n",
      "         [145, 156, 116],\n",
      "         ...,\n",
      "         [129, 137, 100],\n",
      "         [138, 144, 110],\n",
      "         [134, 136, 106]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[146, 149, 166],\n",
      "         [143, 147, 164],\n",
      "         [141, 144, 160],\n",
      "         ...,\n",
      "         [215, 194, 176],\n",
      "         [225, 204, 186],\n",
      "         [224, 203, 185]],\n",
      "\n",
      "        [[143, 149, 165],\n",
      "         [143, 148, 165],\n",
      "         [140, 144, 160],\n",
      "         ...,\n",
      "         [182, 164, 149],\n",
      "         [186, 168, 153],\n",
      "         [179, 161, 146]],\n",
      "\n",
      "        [[139, 144, 163],\n",
      "         [139, 144, 162],\n",
      "         [137, 142, 160],\n",
      "         ...,\n",
      "         [183, 161, 147],\n",
      "         [187, 165, 151],\n",
      "         [186, 164, 150]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 70,  70,  85],\n",
      "         [ 69,  69,  83],\n",
      "         [ 67,  67,  81],\n",
      "         ...,\n",
      "         [ 81,  83,  99],\n",
      "         [ 81,  84,  99],\n",
      "         [ 73,  75,  91]],\n",
      "\n",
      "        [[ 72,  71,  85],\n",
      "         [ 70,  69,  83],\n",
      "         [ 68,  67,  81],\n",
      "         ...,\n",
      "         [ 79,  81,  96],\n",
      "         [ 81,  83,  98],\n",
      "         [ 73,  75,  90]],\n",
      "\n",
      "        [[ 72,  72,  85],\n",
      "         [ 70,  70,  83],\n",
      "         [ 69,  69,  81],\n",
      "         ...,\n",
      "         [ 79,  81,  95],\n",
      "         [ 81,  83,  97],\n",
      "         [ 73,  75,  89]]],\n",
      "\n",
      "\n",
      "       [[[133, 151, 172],\n",
      "         [129, 148, 172],\n",
      "         [131, 153, 173],\n",
      "         ...,\n",
      "         [226, 221, 211],\n",
      "         [228, 224, 215],\n",
      "         [218, 213, 207]],\n",
      "\n",
      "        [[135, 152, 174],\n",
      "         [130, 148, 174],\n",
      "         [132, 152, 176],\n",
      "         ...,\n",
      "         [215, 211, 201],\n",
      "         [213, 208, 200],\n",
      "         [203, 198, 193]],\n",
      "\n",
      "        [[142, 158, 179],\n",
      "         [133, 149, 177],\n",
      "         [131, 149, 175],\n",
      "         ...,\n",
      "         [206, 201, 194],\n",
      "         [203, 199, 193],\n",
      "         [197, 192, 188]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 82,  91,  97],\n",
      "         [ 92, 105, 109],\n",
      "         [ 92, 108, 118],\n",
      "         ...,\n",
      "         [ 86, 105, 113],\n",
      "         [ 92, 109, 116],\n",
      "         [ 90, 105, 114]],\n",
      "\n",
      "        [[ 88,  93,  99],\n",
      "         [ 96, 106, 110],\n",
      "         [ 94, 108, 117],\n",
      "         ...,\n",
      "         [ 87, 103, 117],\n",
      "         [ 91, 105, 115],\n",
      "         [ 91, 103, 116]],\n",
      "\n",
      "        [[ 88,  90,  97],\n",
      "         [ 94, 100, 105],\n",
      "         [ 91,  99, 108],\n",
      "         ...,\n",
      "         [ 89, 103, 117],\n",
      "         [ 87, 100, 111],\n",
      "         [ 90, 102, 114]]],\n",
      "\n",
      "\n",
      "       [[[ 75,  75,  80],\n",
      "         [ 75,  77,  81],\n",
      "         [ 81,  83,  88],\n",
      "         ...,\n",
      "         [ 71,  72,  70],\n",
      "         [ 68,  70,  68],\n",
      "         [ 68,  69,  64]],\n",
      "\n",
      "        [[ 72,  75,  80],\n",
      "         [ 77,  80,  87],\n",
      "         [ 82,  83,  87],\n",
      "         ...,\n",
      "         [ 71,  71,  70],\n",
      "         [ 67,  69,  68],\n",
      "         [ 67,  68,  63]],\n",
      "\n",
      "        [[ 73,  72,  75],\n",
      "         [ 79,  78,  83],\n",
      "         [ 91,  82,  79],\n",
      "         ...,\n",
      "         [ 67,  69,  66],\n",
      "         [ 66,  68,  68],\n",
      "         [ 67,  67,  64]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[118,  80,  46],\n",
      "         [114,  78,  46],\n",
      "         [112,  77,  45],\n",
      "         ...,\n",
      "         [109,  74,  40],\n",
      "         [107,  72,  38],\n",
      "         [106,  71,  37]],\n",
      "\n",
      "        [[122,  82,  45],\n",
      "         [118,  81,  46],\n",
      "         [121,  84,  48],\n",
      "         ...,\n",
      "         [114,  77,  42],\n",
      "         [113,  76,  40],\n",
      "         [115,  78,  41]],\n",
      "\n",
      "        [[123,  81,  45],\n",
      "         [119,  81,  47],\n",
      "         [120,  82,  46],\n",
      "         ...,\n",
      "         [128,  93,  60],\n",
      "         [129,  94,  61],\n",
      "         [123,  91,  58]]]], dtype=uint8)>, <tf.Tensor: shape=(16, 10), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Defining a dataset with batch size 16\n",
    "train_ds = data[\"train\"].batch(16)\n",
    "\n",
    "# Creating a dataset that returns an (image, one-hot label) tuple\n",
    "def format_data(x):\n",
    "    return (x[\"image\"], tf.one_hot(x[\"label\"], depth=10))\n",
    "train_ds = train_ds.map(format_data)\n",
    "\n",
    "# Iterating the dataset\n",
    "for item in train_ds:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a simple CNN on the Cifar10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 34s 11ms/step - loss: 3.2266 - acc: 0.1390\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.2674 - acc: 0.1393\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.2382 - acc: 0.1486\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.2055 - acc: 0.1585\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.1674 - acc: 0.1749\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.1377 - acc: 0.1881\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.1143 - acc: 0.1966\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.0981 - acc: 0.2041\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.0719 - acc: 0.2137\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 2.0526 - acc: 0.2206\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.0452 - acc: 0.2245\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.0277 - acc: 0.2297\n",
      "Epoch 13/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.0246 - acc: 0.2360\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.9919 - acc: 0.2464\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.9815 - acc: 0.2495\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.9629 - acc: 0.2572\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.9624 - acc: 0.2583\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.9485 - acc: 0.2640\n",
      "Epoch 19/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.9298 - acc: 0.2721\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.9335 - acc: 0.2718\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.9151 - acc: 0.2795\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.9217 - acc: 0.2820\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8984 - acc: 0.2861\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8932 - acc: 0.2904\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8851 - acc: 0.2934\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8765 - acc: 0.2979\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8669 - acc: 0.3008\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.9013 - acc: 0.2956\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8565 - acc: 0.3043\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.8555 - acc: 0.3064\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8492 - acc: 0.3077\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.8482 - acc: 0.3132\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.8632 - acc: 0.3095\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.8476 - acc: 0.3141\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.8365 - acc: 0.3149\n",
      "Epoch 36/100\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.8289 - acc: 0.3207\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.8313 - acc: 0.3167\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.8169 - acc: 0.3251\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 20s 7ms/step - loss: 1.8250 - acc: 0.3252\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 1.8026 - acc: 0.3275\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.7968 - acc: 0.3309\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 1.8215 - acc: 0.3284\n",
      "Epoch 43/100\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.8235 - acc: 0.3283\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 1.7961 - acc: 0.3350\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7916 - acc: 0.3356\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7811 - acc: 0.3361\n",
      "Epoch 47/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7871 - acc: 0.3386\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7733 - acc: 0.3419\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7730 - acc: 0.3445\n",
      "Epoch 50/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7577 - acc: 0.3480\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7681 - acc: 0.3451\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7633 - acc: 0.3471\n",
      "Epoch 53/100\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 1.7513 - acc: 0.3503\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.7324 - acc: 0.3536\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7368 - acc: 0.3539\n",
      "Epoch 56/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7506 - acc: 0.3557\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7553 - acc: 0.3518\n",
      "Epoch 58/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7336 - acc: 0.3571\n",
      "Epoch 59/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7477 - acc: 0.3574\n",
      "Epoch 60/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7102 - acc: 0.3652\n",
      "Epoch 61/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7170 - acc: 0.3629\n",
      "Epoch 62/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7012 - acc: 0.3660\n",
      "Epoch 63/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7228 - acc: 0.3655\n",
      "Epoch 64/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7347 - acc: 0.3662\n",
      "Epoch 65/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7224 - acc: 0.3659\n",
      "Epoch 66/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6954 - acc: 0.3674\n",
      "Epoch 67/100\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.7334 - acc: 0.369 - 19s 6ms/step - loss: 1.7332 - acc: 0.3691\n",
      "Epoch 68/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7133 - acc: 0.3712\n",
      "Epoch 69/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7126 - acc: 0.3735\n",
      "Epoch 70/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7191 - acc: 0.3730\n",
      "Epoch 71/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6933 - acc: 0.3765\n",
      "Epoch 72/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6970 - acc: 0.3765\n",
      "Epoch 73/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6894 - acc: 0.3797\n",
      "Epoch 74/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7258 - acc: 0.3764\n",
      "Epoch 75/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6901 - acc: 0.3780\n",
      "Epoch 76/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6735 - acc: 0.3843\n",
      "Epoch 77/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6865 - acc: 0.3830\n",
      "Epoch 78/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6786 - acc: 0.3846\n",
      "Epoch 79/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6851 - acc: 0.3871\n",
      "Epoch 80/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6920 - acc: 0.3864\n",
      "Epoch 81/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6941 - acc: 0.3856\n",
      "Epoch 82/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6665 - acc: 0.3865\n",
      "Epoch 83/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6388 - acc: 0.3916\n",
      "Epoch 84/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6689 - acc: 0.3899\n",
      "Epoch 85/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.6766 - acc: 0.3903\n",
      "Epoch 86/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6562 - acc: 0.3949\n",
      "Epoch 87/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6614 - acc: 0.3922\n",
      "Epoch 88/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6399 - acc: 0.3951\n",
      "Epoch 89/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6668 - acc: 0.3963\n",
      "Epoch 90/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6441 - acc: 0.3999\n",
      "Epoch 91/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6803 - acc: 0.3939\n",
      "Epoch 92/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6338 - acc: 0.3984\n",
      "Epoch 93/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6455 - acc: 0.3998\n",
      "Epoch 94/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6408 - acc: 0.3996\n",
      "Epoch 95/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6437 - acc: 0.4002\n",
      "Epoch 96/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6398 - acc: 0.4034\n",
      "Epoch 97/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6194 - acc: 0.4039\n",
      "Epoch 98/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6085 - acc: 0.4063\n",
      "Epoch 99/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6202 - acc: 0.4063\n",
      "Epoch 100/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.5999 - acc: 0.4101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x201d3f0bc88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Defining a simple convolution neural network to process the CIFAR data\n",
    "model = Sequential([\n",
    "    Conv2D(64,(5,5), activation='relu', input_shape=(32,32,3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "# Fitting the model on the data for 100 epochs\n",
    "model.fit(train_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
