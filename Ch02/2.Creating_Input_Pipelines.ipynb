{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "data_dir = 'data'\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `tf.data` API to retrieve data\n",
    "\n",
    "Here we will be using the `tf.data` API to feed a dataset containing images of flowers. The dataset has a folder containing the images and a CSV file listing filenames and their corresponding label as an integer. We will write a TensorFlow data pipeline that does the following.\n",
    "\n",
    "* Extract filenames and classes from the CSV\n",
    "* Read in the images from the extracted filenames and resize them to 64x64\n",
    "* Convert the class labels to one-hot encoded vectors\n",
    "* Combine the processed images and one-hot encoded vectors to a single dataset\n",
    "* Finally, shuffle the data and output as batches\n",
    "\n",
    "### Downloading the data\n",
    "The dataset is available at https://www.kaggle.com/olgabelitskaya/flower-color-images/data . \n",
    "\n",
    "You need to download the zip file available in this URL and place it in the `data` folder in the `Ch02` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "if os.path.exists('data/flower-color-images.zip'):\n",
    "    zfile = ZipFile('data/flower-color-images.zip')\n",
    "    zfile.extractall('data')\n",
    "else:\n",
    "    print(\"Did you download the dataset as a zip file and place it in the Ch02/data folder?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a tf.data.Dataset \n",
    "\n",
    "Here we are creating the `tf.data` pipeline that executes the above steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "<MapDataset shapes: (64, 64, 3), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "print(tf.__version__)\n",
    "# Getting filenames of all PNG files\n",
    "\n",
    "data_dir = os.path.join('data','flower_images', 'flower_images') + os.path.sep\n",
    "assert os.path.exists(data_dir)\n",
    "csv_ds = tf.data.experimental.CsvDataset(\n",
    "    os.path.join(data_dir,'flower_labels.csv') , (\"\",-1), header=True\n",
    ")\n",
    "fname_ds = csv_ds.map(lambda a,b: a)\n",
    "label_ds = csv_ds.map(lambda a,b: b)\n",
    "\n",
    "def get_image(file_path):\n",
    "    \n",
    "    img = tf.io.read_file(data_dir + file_path)\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [64, 64])\n",
    "\n",
    "\n",
    "image_ds = fname_ds.map(get_image)\n",
    "print(\"The image dataset contains: {}\".format(image_ds))\n",
    "label_ds = label_ds.map(lambda x: tf.one_hot(x, depth=10))\n",
    "data_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "\n",
    "data_ds = data_ds.shuffle(buffer_size= 20)\n",
    "data_ds = data_ds.batch(5)\n",
    "for item in data_ds:\n",
    "    print(item)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and training a model\n",
    "\n",
    "Here we are defining a simple Convolution Neural Network (CNN) model to train it on the image data we just retrieved. You don't have to worry about the technical details of CNNs right now. We will discuss them in detail in the next chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64,(5,5), activation='relu', input_shape=(64,64,3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.fit(data_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras data generators to retrieve data\n",
    "\n",
    "Instead of `tf.data` API let us use the Keras `ImageDataGenerator` to retrieve the data. As you can see, the `ImageDataGenerator` involves much less code than the using the `tf.data` API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\flower_images\\flower_images\\flower_labels.csv\n",
      "Found 210 validated image filenames.\n",
      "(array([[[[-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -7.546631, -8.546631],\n",
      "         ...,\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631]],\n",
      "\n",
      "        [[-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         ...,\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631]],\n",
      "\n",
      "        [[-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         ...,\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         ...,\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631]],\n",
      "\n",
      "        [[-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         ...,\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631]],\n",
      "\n",
      "        [[-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         ...,\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631],\n",
      "         [-8.546631, -8.546631, -8.546631]]],\n",
      "\n",
      "\n",
      "       [[[ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         ...,\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ]],\n",
      "\n",
      "        [[ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         ...,\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ]],\n",
      "\n",
      "        [[ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         ...,\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         ...,\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ]],\n",
      "\n",
      "        [[ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         ...,\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ]],\n",
      "\n",
      "        [[ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         ...,\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ],\n",
      "         [ 0.      ,  0.      ,  0.      ]]]], dtype=float32), array([4, 5], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = os.path.join('data','flower_images')\n",
    "src_dir = os.path.join(data_dir, 'flower_images')\n",
    "img_gen = ImageDataGenerator(\n",
    "    samplewise_center=True, rotation_range=30, \n",
    "    brightness_range=(-0.2,0.2))\n",
    "\n",
    "print(os.path.join(src_dir, 'flower_labels.csv'))\n",
    "labels_df = pd.read_csv(os.path.join(src_dir, 'flower_labels.csv'), header=0)\n",
    "\n",
    "gen_iter = img_gen.flow_from_dataframe(\n",
    "    dataframe=labels_df, directory=src_dir, x_col='file', y_col='label', class_mode='raw', batch_size=2, target_size=(64,64))\n",
    "\n",
    "for item in gen_iter:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `tensorflow-datasets` library\n",
    "\n",
    "Here we will use the `tensorflow-datasets` package. It is a curated list of popular datasets available for machine learning projects. With this package you can download a dataset in a single line. This means you don't have to worry about downloading/extracting/formatting data manually. All of that will be already done when you import data using the `tensorflow-datasets` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists the available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'amazon_us_reviews',\n",
       " 'arc',\n",
       " 'bair_robot_pushing_small',\n",
       " 'beans',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'c4',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'cos_e',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'downsampled_imagenet',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'dummy_dataset_shared_generator',\n",
       " 'dummy_mnist',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'gap',\n",
       " 'gigaword',\n",
       " 'glue',\n",
       " 'groove',\n",
       " 'higgs',\n",
       " 'horses_or_humans',\n",
       " 'i_naturalist2017',\n",
       " 'image_label_folder',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet_resized',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'iris',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'lm1b',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_rationales',\n",
       " 'moving_mnist',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_questions',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'omniglot',\n",
       " 'open_images_v4',\n",
       " 'opinosis',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'patch_camelyon',\n",
       " 'pet_finder',\n",
       " 'places365_small',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'qa4mre',\n",
       " 'quickdraw_bitmap',\n",
       " 'reddit_tifu',\n",
       " 'resisc45',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'shapes3d',\n",
       " 'smallnorb',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'squad',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'starcraft_video',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trivia_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'vgg_face2',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'wider_face',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'xnli',\n",
       " 'xsum',\n",
       " 'yelp_polarity_reviews']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "# See all registered datasets\n",
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Cifar10 dataset and view information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a given dataset by name, along with the DatasetInfo\n",
    "data, info = tfds.load(\"cifar10\", with_info=True)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='cifar10',\n",
      "    version=3.0.0,\n",
      "    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',\n",
      "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    total_num_examples=60000,\n",
      "    splits={\n",
      "        'test': 10000,\n",
      "        'train': 50000,\n",
      "    },\n",
      "    supervised_keys=('image', 'label'),\n",
      "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
      "        author = {Alex Krizhevsky},\n",
      "        title = {Learning multiple layers of features from tiny images},\n",
      "        institution = {},\n",
      "        year = {2009}\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data \n",
    "\n",
    "Here we will print the `data` and see what it provides. Then we will need to batch the data as data is provided as individual samples when you import it from `tensorflow-datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': <DatasetV1Adapter shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>, 'train': <DatasetV1Adapter shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(16, 32, 32, 3), dtype=uint8, numpy=\n",
      "array([[[[143,  96,  70],\n",
      "         [141,  96,  72],\n",
      "         [135,  93,  72],\n",
      "         ...,\n",
      "         [ 96,  37,  19],\n",
      "         [105,  42,  18],\n",
      "         [104,  38,  20]],\n",
      "\n",
      "        [[128,  98,  92],\n",
      "         [146, 118, 112],\n",
      "         [170, 145, 138],\n",
      "         ...,\n",
      "         [108,  45,  26],\n",
      "         [112,  44,  24],\n",
      "         [112,  41,  22]],\n",
      "\n",
      "        [[ 93,  69,  75],\n",
      "         [118,  96, 101],\n",
      "         [179, 160, 162],\n",
      "         ...,\n",
      "         [128,  68,  47],\n",
      "         [125,  61,  42],\n",
      "         [122,  59,  39]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[187, 150, 123],\n",
      "         [184, 148, 123],\n",
      "         [179, 142, 121],\n",
      "         ...,\n",
      "         [198, 163, 132],\n",
      "         [201, 166, 135],\n",
      "         [207, 174, 143]],\n",
      "\n",
      "        [[187, 150, 117],\n",
      "         [181, 143, 115],\n",
      "         [175, 136, 113],\n",
      "         ...,\n",
      "         [201, 164, 132],\n",
      "         [205, 168, 135],\n",
      "         [207, 171, 139]],\n",
      "\n",
      "        [[195, 161, 126],\n",
      "         [187, 153, 123],\n",
      "         [186, 151, 128],\n",
      "         ...,\n",
      "         [212, 177, 147],\n",
      "         [219, 185, 155],\n",
      "         [221, 187, 157]]],\n",
      "\n",
      "\n",
      "       [[[203, 214, 234],\n",
      "         [191, 207, 226],\n",
      "         [178, 200, 224],\n",
      "         ...,\n",
      "         [127, 172, 213],\n",
      "         [126, 171, 212],\n",
      "         [124, 170, 211]],\n",
      "\n",
      "        [[205, 214, 230],\n",
      "         [186, 199, 213],\n",
      "         [180, 197, 214],\n",
      "         ...,\n",
      "         [132, 178, 219],\n",
      "         [130, 176, 219],\n",
      "         [129, 175, 217]],\n",
      "\n",
      "        [[193, 200, 213],\n",
      "         [141, 151, 159],\n",
      "         [124, 137, 145],\n",
      "         ...,\n",
      "         [136, 178, 218],\n",
      "         [134, 177, 218],\n",
      "         [132, 176, 217]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 40,  47,  56],\n",
      "         [ 33,  37,  42],\n",
      "         [ 31,  35,  41],\n",
      "         ...,\n",
      "         [ 73,  99, 132],\n",
      "         [ 64,  91, 126],\n",
      "         [ 69,  97, 133]],\n",
      "\n",
      "        [[ 37,  44,  53],\n",
      "         [ 31,  34,  40],\n",
      "         [ 30,  34,  40],\n",
      "         ...,\n",
      "         [ 72,  98, 132],\n",
      "         [ 64,  92, 127],\n",
      "         [ 68,  96, 132]],\n",
      "\n",
      "        [[ 34,  41,  50],\n",
      "         [ 29,  32,  38],\n",
      "         [ 28,  32,  38],\n",
      "         ...,\n",
      "         [ 68,  94, 127],\n",
      "         [ 62,  89, 123],\n",
      "         [ 63,  91, 126]]],\n",
      "\n",
      "\n",
      "       [[[106, 103, 104],\n",
      "         [103,  97,  99],\n",
      "         [102,  93,  96],\n",
      "         ...,\n",
      "         [135, 126, 129],\n",
      "         [139, 130, 133],\n",
      "         [131, 122, 125]],\n",
      "\n",
      "        [[106, 104, 105],\n",
      "         [105,  99, 101],\n",
      "         [115, 106, 109],\n",
      "         ...,\n",
      "         [137, 129, 132],\n",
      "         [135, 126, 129],\n",
      "         [124, 115, 118]],\n",
      "\n",
      "        [[108, 105, 106],\n",
      "         [117, 111, 113],\n",
      "         [123, 114, 117],\n",
      "         ...,\n",
      "         [132, 123, 126],\n",
      "         [126, 117, 120],\n",
      "         [121, 112, 115]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[136, 163, 117],\n",
      "         [135, 162, 115],\n",
      "         [139, 166, 117],\n",
      "         ...,\n",
      "         [140, 144, 111],\n",
      "         [133, 135, 105],\n",
      "         [126, 125,  98]],\n",
      "\n",
      "        [[130, 150, 104],\n",
      "         [131, 150, 107],\n",
      "         [131, 150, 109],\n",
      "         ...,\n",
      "         [141, 150, 112],\n",
      "         [144, 152, 115],\n",
      "         [140, 144, 111]],\n",
      "\n",
      "        [[139, 151, 108],\n",
      "         [133, 144, 103],\n",
      "         [145, 156, 116],\n",
      "         ...,\n",
      "         [129, 137, 100],\n",
      "         [138, 144, 110],\n",
      "         [134, 136, 106]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[146, 149, 166],\n",
      "         [143, 147, 164],\n",
      "         [141, 144, 160],\n",
      "         ...,\n",
      "         [215, 194, 176],\n",
      "         [225, 204, 186],\n",
      "         [224, 203, 185]],\n",
      "\n",
      "        [[143, 149, 165],\n",
      "         [143, 148, 165],\n",
      "         [140, 144, 160],\n",
      "         ...,\n",
      "         [182, 164, 149],\n",
      "         [186, 168, 153],\n",
      "         [179, 161, 146]],\n",
      "\n",
      "        [[139, 144, 163],\n",
      "         [139, 144, 162],\n",
      "         [137, 142, 160],\n",
      "         ...,\n",
      "         [183, 161, 147],\n",
      "         [187, 165, 151],\n",
      "         [186, 164, 150]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 70,  70,  85],\n",
      "         [ 69,  69,  83],\n",
      "         [ 67,  67,  81],\n",
      "         ...,\n",
      "         [ 81,  83,  99],\n",
      "         [ 81,  84,  99],\n",
      "         [ 73,  75,  91]],\n",
      "\n",
      "        [[ 72,  71,  85],\n",
      "         [ 70,  69,  83],\n",
      "         [ 68,  67,  81],\n",
      "         ...,\n",
      "         [ 79,  81,  96],\n",
      "         [ 81,  83,  98],\n",
      "         [ 73,  75,  90]],\n",
      "\n",
      "        [[ 72,  72,  85],\n",
      "         [ 70,  70,  83],\n",
      "         [ 69,  69,  81],\n",
      "         ...,\n",
      "         [ 79,  81,  95],\n",
      "         [ 81,  83,  97],\n",
      "         [ 73,  75,  89]]],\n",
      "\n",
      "\n",
      "       [[[133, 151, 172],\n",
      "         [129, 148, 172],\n",
      "         [131, 153, 173],\n",
      "         ...,\n",
      "         [226, 221, 211],\n",
      "         [228, 224, 215],\n",
      "         [218, 213, 207]],\n",
      "\n",
      "        [[135, 152, 174],\n",
      "         [130, 148, 174],\n",
      "         [132, 152, 176],\n",
      "         ...,\n",
      "         [215, 211, 201],\n",
      "         [213, 208, 200],\n",
      "         [203, 198, 193]],\n",
      "\n",
      "        [[142, 158, 179],\n",
      "         [133, 149, 177],\n",
      "         [131, 149, 175],\n",
      "         ...,\n",
      "         [206, 201, 194],\n",
      "         [203, 199, 193],\n",
      "         [197, 192, 188]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 82,  91,  97],\n",
      "         [ 92, 105, 109],\n",
      "         [ 92, 108, 118],\n",
      "         ...,\n",
      "         [ 86, 105, 113],\n",
      "         [ 92, 109, 116],\n",
      "         [ 90, 105, 114]],\n",
      "\n",
      "        [[ 88,  93,  99],\n",
      "         [ 96, 106, 110],\n",
      "         [ 94, 108, 117],\n",
      "         ...,\n",
      "         [ 87, 103, 117],\n",
      "         [ 91, 105, 115],\n",
      "         [ 91, 103, 116]],\n",
      "\n",
      "        [[ 88,  90,  97],\n",
      "         [ 94, 100, 105],\n",
      "         [ 91,  99, 108],\n",
      "         ...,\n",
      "         [ 89, 103, 117],\n",
      "         [ 87, 100, 111],\n",
      "         [ 90, 102, 114]]],\n",
      "\n",
      "\n",
      "       [[[ 75,  75,  80],\n",
      "         [ 75,  77,  81],\n",
      "         [ 81,  83,  88],\n",
      "         ...,\n",
      "         [ 71,  72,  70],\n",
      "         [ 68,  70,  68],\n",
      "         [ 68,  69,  64]],\n",
      "\n",
      "        [[ 72,  75,  80],\n",
      "         [ 77,  80,  87],\n",
      "         [ 82,  83,  87],\n",
      "         ...,\n",
      "         [ 71,  71,  70],\n",
      "         [ 67,  69,  68],\n",
      "         [ 67,  68,  63]],\n",
      "\n",
      "        [[ 73,  72,  75],\n",
      "         [ 79,  78,  83],\n",
      "         [ 91,  82,  79],\n",
      "         ...,\n",
      "         [ 67,  69,  66],\n",
      "         [ 66,  68,  68],\n",
      "         [ 67,  67,  64]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[118,  80,  46],\n",
      "         [114,  78,  46],\n",
      "         [112,  77,  45],\n",
      "         ...,\n",
      "         [109,  74,  40],\n",
      "         [107,  72,  38],\n",
      "         [106,  71,  37]],\n",
      "\n",
      "        [[122,  82,  45],\n",
      "         [118,  81,  46],\n",
      "         [121,  84,  48],\n",
      "         ...,\n",
      "         [114,  77,  42],\n",
      "         [113,  76,  40],\n",
      "         [115,  78,  41]],\n",
      "\n",
      "        [[123,  81,  45],\n",
      "         [119,  81,  47],\n",
      "         [120,  82,  46],\n",
      "         ...,\n",
      "         [128,  93,  60],\n",
      "         [129,  94,  61],\n",
      "         [123,  91,  58]]]], dtype=uint8)>, <tf.Tensor: shape=(16, 10), dtype=float32, numpy=\n",
      "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = data[\"train\"].batch(16)\n",
    "def format_data(x):\n",
    "    return (x[\"image\"], tf.one_hot(x[\"label\"], depth=10))\n",
    "train_ds = train_ds.map(format_data)\n",
    "for item in train_ds:\n",
    "    print(item)\n",
    "    break\n",
    "    #print(item.shape)\n",
    "    #print(item[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a simple CNN on the Cifar10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3125/3125 [==============================] - 34s 11ms/step - loss: 3.2266 - acc: 0.1390\n",
      "Epoch 2/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.2674 - acc: 0.1393\n",
      "Epoch 3/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.2382 - acc: 0.1486\n",
      "Epoch 4/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.2055 - acc: 0.1585\n",
      "Epoch 5/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.1674 - acc: 0.1749\n",
      "Epoch 6/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.1377 - acc: 0.1881\n",
      "Epoch 7/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.1143 - acc: 0.1966\n",
      "Epoch 8/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.0981 - acc: 0.2041\n",
      "Epoch 9/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 2.0719 - acc: 0.2137\n",
      "Epoch 10/100\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 2.0526 - acc: 0.2206\n",
      "Epoch 11/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.0452 - acc: 0.2245\n",
      "Epoch 12/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.0277 - acc: 0.2297\n",
      "Epoch 13/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 2.0246 - acc: 0.2360\n",
      "Epoch 14/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.9919 - acc: 0.2464\n",
      "Epoch 15/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.9815 - acc: 0.2495\n",
      "Epoch 16/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.9629 - acc: 0.2572\n",
      "Epoch 17/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.9624 - acc: 0.2583\n",
      "Epoch 18/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.9485 - acc: 0.2640\n",
      "Epoch 19/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.9298 - acc: 0.2721\n",
      "Epoch 20/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.9335 - acc: 0.2718\n",
      "Epoch 21/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.9151 - acc: 0.2795\n",
      "Epoch 22/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.9217 - acc: 0.2820\n",
      "Epoch 23/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8984 - acc: 0.2861\n",
      "Epoch 24/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8932 - acc: 0.2904\n",
      "Epoch 25/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8851 - acc: 0.2934\n",
      "Epoch 26/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8765 - acc: 0.2979\n",
      "Epoch 27/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8669 - acc: 0.3008\n",
      "Epoch 28/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.9013 - acc: 0.2956\n",
      "Epoch 29/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8565 - acc: 0.3043\n",
      "Epoch 30/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.8555 - acc: 0.3064\n",
      "Epoch 31/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.8492 - acc: 0.3077\n",
      "Epoch 32/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.8482 - acc: 0.3132\n",
      "Epoch 33/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.8632 - acc: 0.3095\n",
      "Epoch 34/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.8476 - acc: 0.3141\n",
      "Epoch 35/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.8365 - acc: 0.3149\n",
      "Epoch 36/100\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.8289 - acc: 0.3207\n",
      "Epoch 37/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.8313 - acc: 0.3167\n",
      "Epoch 38/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.8169 - acc: 0.3251\n",
      "Epoch 39/100\n",
      "3125/3125 [==============================] - 20s 7ms/step - loss: 1.8250 - acc: 0.3252\n",
      "Epoch 40/100\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 1.8026 - acc: 0.3275\n",
      "Epoch 41/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.7968 - acc: 0.3309\n",
      "Epoch 42/100\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 1.8215 - acc: 0.3284\n",
      "Epoch 43/100\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.8235 - acc: 0.3283\n",
      "Epoch 44/100\n",
      "3125/3125 [==============================] - 23s 7ms/step - loss: 1.7961 - acc: 0.3350\n",
      "Epoch 45/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7916 - acc: 0.3356\n",
      "Epoch 46/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7811 - acc: 0.3361\n",
      "Epoch 47/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7871 - acc: 0.3386\n",
      "Epoch 48/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7733 - acc: 0.3419\n",
      "Epoch 49/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7730 - acc: 0.3445\n",
      "Epoch 50/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7577 - acc: 0.3480\n",
      "Epoch 51/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7681 - acc: 0.3451\n",
      "Epoch 52/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7633 - acc: 0.3471\n",
      "Epoch 53/100\n",
      "3125/3125 [==============================] - 22s 7ms/step - loss: 1.7513 - acc: 0.3503\n",
      "Epoch 54/100\n",
      "3125/3125 [==============================] - 21s 7ms/step - loss: 1.7324 - acc: 0.3536\n",
      "Epoch 55/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7368 - acc: 0.3539\n",
      "Epoch 56/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7506 - acc: 0.3557\n",
      "Epoch 57/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7553 - acc: 0.3518\n",
      "Epoch 58/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7336 - acc: 0.3571\n",
      "Epoch 59/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7477 - acc: 0.3574\n",
      "Epoch 60/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7102 - acc: 0.3652\n",
      "Epoch 61/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7170 - acc: 0.3629\n",
      "Epoch 62/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7012 - acc: 0.3660\n",
      "Epoch 63/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7228 - acc: 0.3655\n",
      "Epoch 64/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7347 - acc: 0.3662\n",
      "Epoch 65/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7224 - acc: 0.3659\n",
      "Epoch 66/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6954 - acc: 0.3674\n",
      "Epoch 67/100\n",
      "3125/3125 [==============================] - ETA: 0s - loss: 1.7334 - acc: 0.369 - 19s 6ms/step - loss: 1.7332 - acc: 0.3691\n",
      "Epoch 68/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7133 - acc: 0.3712\n",
      "Epoch 69/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7126 - acc: 0.3735\n",
      "Epoch 70/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.7191 - acc: 0.3730\n",
      "Epoch 71/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6933 - acc: 0.3765\n",
      "Epoch 72/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6970 - acc: 0.3765\n",
      "Epoch 73/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6894 - acc: 0.3797\n",
      "Epoch 74/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.7258 - acc: 0.3764\n",
      "Epoch 75/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6901 - acc: 0.3780\n",
      "Epoch 76/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6735 - acc: 0.3843\n",
      "Epoch 77/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6865 - acc: 0.3830\n",
      "Epoch 78/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6786 - acc: 0.3846\n",
      "Epoch 79/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6851 - acc: 0.3871\n",
      "Epoch 80/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6920 - acc: 0.3864\n",
      "Epoch 81/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6941 - acc: 0.3856\n",
      "Epoch 82/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6665 - acc: 0.3865\n",
      "Epoch 83/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6388 - acc: 0.3916\n",
      "Epoch 84/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6689 - acc: 0.3899\n",
      "Epoch 85/100\n",
      "3125/3125 [==============================] - 20s 6ms/step - loss: 1.6766 - acc: 0.3903\n",
      "Epoch 86/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6562 - acc: 0.3949\n",
      "Epoch 87/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6614 - acc: 0.3922\n",
      "Epoch 88/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6399 - acc: 0.3951\n",
      "Epoch 89/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6668 - acc: 0.3963\n",
      "Epoch 90/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6441 - acc: 0.3999\n",
      "Epoch 91/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6803 - acc: 0.3939\n",
      "Epoch 92/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6338 - acc: 0.3984\n",
      "Epoch 93/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6455 - acc: 0.3998\n",
      "Epoch 94/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6408 - acc: 0.3996\n",
      "Epoch 95/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6437 - acc: 0.4002\n",
      "Epoch 96/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6398 - acc: 0.4034\n",
      "Epoch 97/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6194 - acc: 0.4039\n",
      "Epoch 98/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6085 - acc: 0.4063\n",
      "Epoch 99/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.6202 - acc: 0.4063\n",
      "Epoch 100/100\n",
      "3125/3125 [==============================] - 19s 6ms/step - loss: 1.5999 - acc: 0.4101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x201d3f0bc88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64,(5,5), activation='relu', input_shape=(32,32,3)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.fit(train_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
